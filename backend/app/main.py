from fastapi import FastAPI, Header, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from app.models.schemas import StoryRequest, GeneratedStory, WordForm
from app.models.user import UserStatus, PurchaseRequest
from app.services.generator_rules import RuleBasedGenerator
from app.services.llm import LLMService
from app.services.nlp_processor import NLPService
from app.services.tts import TTSService
from app.services.cache import CacheService
from app.services.user_service import UserService

app = FastAPI(
    title="Make Story AI API",
    version="0.1.0",
    description="API for Android Language Learning App"
)

# Mount static for audio
app.mount("/static", StaticFiles(directory="backend/static"), name="static")

# CORS (Allow Android emulator/device)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

rule_generator = RuleBasedGenerator()
llm_service = LLMService()
nlp_service = NLPService()
tts_service = TTSService()
cache_service = CacheService()
user_service = UserService()

@app.get("/api/v1/user/status", response_model=UserStatus)
async def get_status(x_device_id: str = Header(...)):
    return user_service.get_user_status(x_device_id)

@app.post("/api/v1/user/upgrade", response_model=UserStatus)
async def upgrade_user(req: PurchaseRequest):
    """Mock endpoint: –ö—É–ø–∏—Ç—å –ø—Ä–µ–º–∏—É–º"""
    user_service.upgrade_user(req.device_id)
    return user_service.get_user_status(req.device_id)

@app.post("/api/v1/generate", response_model=GeneratedStory)
async def generate_story(
    request: StoryRequest, 
    x_device_id: str = Header(...)
):
    """
    –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏.
    1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ö–≠–®–ê (Redis).
    2. –ï—Å–ª–∏ –Ω–µ—Ç -> –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (Rules -> LLM -> NLP -> TTS).
    3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ö–≠–®.
    """
    # 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤
    status = user_service.get_user_status(x_device_id)
    if status.daily_count >= status.limit:
        raise HTTPException(status_code=402, detail="Daily limit reached. Buy Premium!")

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cached_story = await cache_service.get_story(request.topic, request.level, request.language)
    if cached_story:
        print("‚ö° Cache Hit!")
        return GeneratedStory(**cached_story)

    print("üê¢ Cache Miss. Generating...")

    # 2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (Rules)
    constraints = rule_generator.generate_structure(request)
    
    # 3. –¢–µ–∫—Å—Ç (LLM)
    raw_text = await llm_service.generate_story_text(constraints)
    
    # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ (NLP)
    processed_html, forms = nlp_service.process_story(raw_text, constraints)
    
    # 5. –ê—É–¥–∏–æ (TTS)
    audio_path = await tts_service.generate_audio(raw_text, request.language)
    
    # –°–æ–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç
    story_response = GeneratedStory(
        title=f"{constraints['topic'].title()} Story",
        story_html=f"<p>{processed_html}</p>",
        forms=forms,
        audio_url=audio_path
    )
    
    # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à (–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–æ–¥–µ–ª—å –≤ dict)
    await cache_service.save_story(
        request.topic, 
        request.level, 
        request.language, 
        story_response.model_dump()
    )
    
    # 7. –°–ø–∏—Å—ã–≤–∞–µ–º –ª–∏–º–∏—Ç
    user_service.increment_usage(x_device_id)

    return story_response

@app.get("/")
async def root():
    return {"message": "Make Story AI Backend is Running üöÄ"}

@app.get("/health")
async def health():
    return {"status": "ok"}
